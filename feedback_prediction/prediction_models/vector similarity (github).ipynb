{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "paper 2 - ALTERNATIVE SIGNATURE-BASED ('VECTOR SPACE') APPROACH\n",
    "\n",
    "Clustering GP practices according to similarities in signature paths\n",
    "\n",
    "\n",
    "Given data are available up to mid December 2017, models are trained to predict feedback for September \n",
    "and October 2017. Model testing takes place for feedback in November and December 2017. Models are trained and\n",
    "tested for GP practices which:\n",
    "    - have at least 2 reviews from period preceding September 2017\n",
    "    - received some feedback in November and December 2017\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cluster_pred(csv_file, depvar='q9', ignore_nan=True, train = None, test = None, day_min=735008,log=False,degs=2, sigs_with_depvar=True, cutoff = 10):\n",
    "    \"\"\"\n",
    "    \n",
    "    To do:\n",
    "        - can add options for different distance measures between pairs of vectors\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #preliminary tests\n",
    "    if test == None and test == train:\n",
    "        test = list(range(736621,736681))\n",
    "        train = list(range(day_min,736621))\n",
    "    elif type(test) == list and type(train) == list:\n",
    "        if len(test) == 0 or len(train) == 0:\n",
    "            print('TypeError: test and train should be non-empty lists of day ID numbers')\n",
    "            return()\n",
    "    else:\n",
    "        print(\"TypeError: define test and train attributes or leave default values, i.e. None\")\n",
    "        return()\n",
    "    \n",
    "    # test for overlap of train_range and test_range\n",
    "    if min(test) <= max(train):\n",
    "        print(\"AttributeError: select non-overlapping ranges of days for test and train. Also, days included in train should pre-date days included in test\")\n",
    "        return()\n",
    "    \n",
    "    # test whether day_min is prior to day ranges defined in y_train and y_test\n",
    "    if day_min >= min(test) or day_min > min(train):\n",
    "        print(\"AttributeError: select ranges of days for test and train which post-date day_min\")\n",
    "        return()\n",
    "    \n",
    "    window = max(test) - min(test) + 1\n",
    "    \n",
    "    \n",
    "    # generate data paths and signatures for each GP practice - \"train\" period. Retain only data points where dependent variable data are available\n",
    "    x_train = make_paths(csv_file, depvar=depvar, min_day=day_min, max_day=max(train)-window, ignore_nan = ignore_nan)\n",
    "    x_train = make_sigs(x_train, degs, 'sigs_xtrain.csv', log=log, include_depvar=sigs_with_depvar)\n",
    "    y_train = make_depvar(csv_file,depvar, list(range(max(train)-window+1,max(train)+1)))\n",
    "\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_tmp = [str(x) for x in list(y_train.columns)]\n",
    "    x_tmp = [str(x) for x in list(x_train.columns)]\n",
    "    y_train.columns = y_tmp\n",
    "    x_train.columns = x_tmp\n",
    "    train_summary = pd.merge(left=y_train,right=x_train, left_on='0', right_on='0', how='inner')\n",
    "    train_summary.rename(columns={'1_x': 'y_train', '1_y': '1'}, inplace=True)\n",
    "    \n",
    "    # generate data paths and signatures for each GP practice - \"test\" period. Retain only data points where dependent variable data are available\n",
    "    x_test = make_paths(csv_file, depvar=depvar, min_day=day_min+window, max_day=min(test)-1, ignore_nan = ignore_nan)\n",
    "    x_test = make_sigs(x_test, degs, 'sigs_xtest.csv', log=log, include_depvar=sigs_with_depvar)\n",
    "    y_test = make_depvar(csv_file,depvar, list(range(min(test),max(test)+1)))\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    y_tmp = [str(x) for x in list(y_test.columns)]\n",
    "    x_tmp = [str(x) for x in list(x_test.columns)]\n",
    "    y_test.columns = y_tmp\n",
    "    x_test.columns = x_tmp\n",
    "    test_summary = pd.merge(left=y_test,right=x_test, left_on='0', right_on='0', how='inner')\n",
    "    test_summary.rename(columns={'1_x': 'y_test', '1_y': '1'}, inplace=True)\n",
    "    \n",
    "    # predict train dates (with variable \"n\" parameter which corresponds to the number of nearest vectors considered)\n",
    "    train_summary = train_summary.values.tolist()\n",
    "    # compute cosine similarities for each GP practice\n",
    "    x = []\n",
    "    y = []\n",
    "    depvar_vals = []\n",
    "    for i,v in enumerate(train_summary):\n",
    "        if i < 10000000000: # sample size can be modified for exercise\n",
    "            x.append(v[2:])\n",
    "            y.append(v[2:])\n",
    "            depvar_vals.append(int(v[1])) #depvar values get rounded to the nearest integer\n",
    "    r = cosine_similarity(np.array(x), np.array(y)) #computes cosine similarity score of every vector in 'y' to each vector in 'x'\n",
    "    \n",
    "    # associate predictions with gp_ids and depvars rounded to nearest integer\n",
    "    probs = {}\n",
    "    for gp, row in enumerate(r): #every 'row' contains similarities of all vectors to a given vector of 'x' \n",
    "        i = []\n",
    "        ii = []\n",
    "        iii = []\n",
    "        iv = []\n",
    "        v = []\n",
    "        for ind, element in enumerate(row):\n",
    "            if depvar_vals[ind] == 1 and gp != ind:\n",
    "                i.append(element)\n",
    "            elif depvar_vals[ind] == 2 and gp != ind:\n",
    "                ii.append(element)\n",
    "            elif depvar_vals[ind] == 3 and gp != ind:\n",
    "                iii.append(element)\n",
    "            elif depvar_vals[ind] == 4 and gp != ind:\n",
    "                iv.append(element)\n",
    "            elif depvar_vals[ind] == 5 and gp != ind:\n",
    "                v.append(element)\n",
    "            elif gp == ind:\n",
    "                pass\n",
    "            else:\n",
    "                print('something went wrong with prediction calculations')\n",
    "        \n",
    "        i = sorted(i, reverse=True)[:cutoff]\n",
    "        i = [xx for xx in i if xx > 0]\n",
    "        ii = sorted(ii, reverse=True)[:cutoff]\n",
    "        ii = [xx for xx in ii if xx > 0]\n",
    "        iii = sorted(iii, reverse=True)[:cutoff]\n",
    "        iii = [xx for xx in iii if xx > 0]\n",
    "        iv = sorted(iv, reverse=True)[:cutoff]\n",
    "        iv = [xx for xx in iv if xx > 0]\n",
    "        v = sorted(v, reverse=True)[:cutoff]\n",
    "        v = [xx for xx in v if xx > 0]\n",
    "        overall = i[:]\n",
    "        overall.extend(ii)\n",
    "        overall.extend(iii)\n",
    "        overall.extend(iv)\n",
    "        overall.extend(v)\n",
    "        overall = sum(overall)\n",
    "\n",
    "        tmp = []\n",
    "        for xx in [i,ii,iii,iv,v]:\n",
    "            prob = sum(xx) / overall\n",
    "            tmp.append(prob)\n",
    "        probs[train_summary[gp][0]] = tmp\n",
    "    \n",
    "    #populate the train object to return the predictions and actual values\n",
    "    train = []\n",
    "    for i, xx in enumerate(probs):\n",
    "        tmp = [str(int(xx))]\n",
    "        tmp.extend(probs[xx])\n",
    "        tmp.extend([probs[xx].index(max(probs[xx]))+1 , int(train_summary[i][1])])\n",
    "        train.append(tmp)\n",
    "    train = pd.DataFrame(train, columns=['gp_id', \"prob1\", \"prob2\", \"prob3\", \"prob4\", \"prob5\", \"yhat_train\", \"y_train\"])\n",
    "    \n",
    "\n",
    "    # predict values for the test period (last 60 days of feedback) by looking at the similarity between pairs of signatures\n",
    "    # do it the bayesian way (select the highest probability result, and then calculate test MSE error)\n",
    "    \n",
    "    test_summary = test_summary.values.tolist()\n",
    "    x = []\n",
    "#     test_vals = []\n",
    "    for i,v in enumerate(test_summary):\n",
    "        if i < 10000000000: # sample size can be modified for exercise\n",
    "            x.append(v[2:])\n",
    "#             test_vals.append(int(v[1])) #depvar values get rounded to the nearest integer\n",
    "\n",
    "    r = cosine_similarity(np.array(x), np.array(y)) #computes cosine similarity score of every vector in 'y' to each vector in 'x'\n",
    "\n",
    "#     associate predictions with gp_ids and depvars rounded to nearest integer\n",
    "    probs = {}\n",
    "    for gp, row in enumerate(r): #every 'row' contains similarities of all vectors to a given vector of 'x' \n",
    "        i = []\n",
    "        ii = []\n",
    "        iii = []\n",
    "        iv = []\n",
    "        v = []\n",
    "        for ind, element in enumerate(row):\n",
    "            if depvar_vals[ind] == 1:\n",
    "                i.append(element)\n",
    "            elif depvar_vals[ind] == 2:\n",
    "                ii.append(element)\n",
    "            elif depvar_vals[ind] == 3:\n",
    "                iii.append(element)\n",
    "            elif depvar_vals[ind] == 4:\n",
    "                iv.append(element)\n",
    "            elif depvar_vals[ind] == 5:\n",
    "                v.append(element)\n",
    "            else:\n",
    "                print('something went wrong with prediction calculations')\n",
    "        \n",
    "        i = sorted(i, reverse=True)[:cutoff]\n",
    "        i = [xx for xx in i if xx > 0]\n",
    "        ii = sorted(ii, reverse=True)[:cutoff]\n",
    "        ii = [xx for xx in ii if xx > 0]\n",
    "        iii = sorted(iii, reverse=True)[:cutoff]\n",
    "        iii = [xx for xx in iii if xx > 0]\n",
    "        iv = sorted(iv, reverse=True)[:cutoff]\n",
    "        iv = [xx for xx in iv if xx > 0]\n",
    "        v = sorted(v, reverse=True)[:cutoff]\n",
    "        v = [xx for xx in v if xx > 0]\n",
    "        overall = i[:]\n",
    "        overall.extend(ii)\n",
    "        overall.extend(iii)\n",
    "        overall.extend(iv)\n",
    "        overall.extend(v)\n",
    "        overall = sum(overall)\n",
    "        \n",
    "        tmp = []\n",
    "        for xx in [i,ii,iii,iv,v]:\n",
    "            prob = sum(xx) / overall\n",
    "            tmp.append(prob)\n",
    "        probs[test_summary[gp][0]] = tmp\n",
    "    \n",
    "    #populate the train object to return the predictions and actual values\n",
    "    test = []\n",
    "    for i, xx in enumerate(probs):\n",
    "        tmp = [str(int(xx))]\n",
    "        tmp.extend(probs[xx])\n",
    "        tmp.extend([probs[xx].index(max(probs[xx]))+1 , int(test_summary[i][1])])\n",
    "        test.append(tmp)\n",
    "    test = pd.DataFrame(test, columns=['gp_id', \"prob1\", \"prob2\", \"prob3\", \"prob4\", \"prob5\", \"yhat_test\", \"y_test\"])\n",
    "    \n",
    "    results = [train,test]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# clus_res = cluster_pred('r_output.csv',depvar='q9', cutoff = 2)\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clus_mse_calculator (chosen_cutoffs):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns list of train and test MSE errors for predictions for a list of chosen 'cutoff' values.\n",
    "    The 'cutoff' parameter is used in cluster_pred() function\n",
    "    \n",
    "    \"\"\"\n",
    "    clus_res_combo = []\n",
    "    for c in chosen_cutoffs:\n",
    "        print('compute results for cutoff=' +str(c))\n",
    "        clus_res = cluster_pred('r_output.csv',depvar='q9', cutoff = c)\n",
    "        train_mse = mean_squared_error(np.array(clus_res[0]['yhat_train']),np.array(clus_res[0]['y_train']))\n",
    "        test_mse = mean_squared_error(np.array(clus_res[1]['yhat_test']),np.array(clus_res[1]['y_test']))\n",
    "        clus_res_combo.append([c, train_mse, test_mse])\n",
    "        print([c, train_mse, test_mse])\n",
    "\n",
    "print('all candidate models completed')\n",
    "\n",
    "# clus_res_combo = clus_mse_calculator(list(range(1,31)))\n",
    "# clus_res_combo1001to1030 = clus_mse_calculator(list(range(1001,1031)))\n",
    "# clus_res_combo101to130 = clus_mse_calculator(list(range(101,131)))\n",
    "\n",
    "for x in clus_res_combo:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(t_results, columns = ['test_err','train_err'])\n",
    "x['t_val'] = t_candidates\n",
    "ns = [x[0] for x in clus_res_combo]\n",
    "tr = [x[1] for x in clus_res_combo]\n",
    "te = [x[2] for x in clus_res_combo]\n",
    "\n",
    "print(\"Prediction errors in model training\")\n",
    "plt.plot(ns, tr, 'ro')\n",
    "plt.xlabel('Number of top \"n\" models used to identify the most probable Likert-scale response')\n",
    "plt.ylabel('average mean squared error')\n",
    "plt.show()\n",
    "\n",
    "print(\"Prediction errors in model testing\")\n",
    "plt.plot(ns, te, 'ro')\n",
    "plt.xlabel('Number of top \"n\" models used to identify the most probable Likert-scale response')\n",
    "plt.ylabel('average mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best clustering-based model\n",
    "\n",
    "clus_res = cluster_pred('r_output.csv',depvar='q9', cutoff = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(np.array(clus_res[0]['yhat_train']),np.array(clus_res[0]['y_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
